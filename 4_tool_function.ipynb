{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc1f60cf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4abdb694",
   "metadata": {},
   "source": [
    "# 4 工具函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d348c6",
   "metadata": {},
   "source": [
    "初始化量化工具，方便使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d308464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da490ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个QuantizationParams类用于保存量化过程中的参数\n",
    "@dataclass\n",
    "class QuantizationParams:\n",
    "    scale: torch.Tensor\n",
    "    zero_point: torch.Tensor\n",
    "    q_min: int\n",
    "    q_max: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "233dbf18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5410, -0.2934, -2.1788],\n",
       "        [ 0.5684, -1.0845, -1.3986],\n",
       "        [ 0.4033,  0.8380, -0.7193]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化一个随机Tensor\n",
    "torch.manual_seed(0)\n",
    "x = torch.randn(3, 3, dtype=torch.float32)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ee2a8d",
   "metadata": {},
   "source": [
    "## 4.1 对称量化\n",
    "\n",
    "定义对称量化函数用于返回对称量化过程中的QuantizationParams。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e0d3068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对称量化参数计算,接收一个张量，返回量化参数对象，可选通道进行量化\n",
    "def get_symmetric_qparams(x: torch.Tensor,\n",
    "                          per_channel: bool = False,\n",
    "                          channel_dim: int = 0,\n",
    "                          dtype = torch.int8,\n",
    "                          eps: float = 1e-8):\n",
    "\n",
    "    # 获取最大和最小值\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "    q_min = torch.iinfo(dtype).min\n",
    "\n",
    "    if per_channel:\n",
    "        # 在channel_dim维度上做\n",
    "        max_val = x.abs().amax(dim=tuple(d for d in range(x.dim()) if d != channel_dim), keepdim=True)\n",
    "    else:\n",
    "        max_val = x.abs().max()\n",
    "    \n",
    "    # 避免除0\n",
    "    scale = max_val / max(q_max,1)\n",
    "    scale = torch.clip(scale,eps)\n",
    "\n",
    "    # 对称量化，zero_point恒为0\n",
    "    zero_point = torch.zeros_like(scale)\n",
    "    return QuantizationParams(scale=scale, zero_point=zero_point, q_min=q_min, q_max=q_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d38bfa69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizationParams(scale=tensor(0.0172), zero_point=tensor(0.), q_min=-128, q_max=127)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取x的整体量化参数，x_shape=[3,3]\n",
    "x_sym_params = get_symmetric_qparams(x)\n",
    "x_sym_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d46ada54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizationParams(scale=tensor([[0.0172],\n",
       "        [0.0110],\n",
       "        [0.0066]]), zero_point=tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]]), q_min=-128, q_max=127)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以dim=0作为通道，逐通道获取x的量化参数，每个通道维护其自身的s和z，x_shape=[3,3]\n",
    "x_sym_params = get_symmetric_qparams(x,True,0)\n",
    "x_sym_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bd81a",
   "metadata": {},
   "source": [
    "## 4.2 非对称量化\n",
    "定义非对称量化函数用于返回对称量化过程中的QuantizationParams。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4f2afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非对称量化参数计算,接收一个张量，返回量化参数对象，可选通道进行量化\n",
    "def get_asymmetric_qparams(x: torch.Tensor,\n",
    "                            per_channel: bool = False,\n",
    "                            channel_dim: int = 0,\n",
    "                            dtype = torch.int8,\n",
    "                            eps: float = 1e-8) -> QuantizationParams:\n",
    "\n",
    "    # 获取最大和最小值\n",
    "    q_max = torch.iinfo(dtype).max\n",
    "    q_min = torch.iinfo(dtype).min\n",
    "\n",
    "    if per_channel:\n",
    "        reduce_dims = tuple(d for d in range(x.dim()) if d != channel_dim)\n",
    "        x_min = x.amin(dim=reduce_dims, keepdim=True)\n",
    "        x_max = x.amax(dim=reduce_dims, keepdim=True)\n",
    "    else:\n",
    "        x_min = x.min()\n",
    "        x_max = x.max()\n",
    "    \n",
    "    # 避免0除的情况\n",
    "    scale = (x_max-x_min) / max(q_max - q_min,1)  \n",
    "    scale = torch.clip(scale,eps) # 当x_max == x_min的时候会出现0\n",
    "\n",
    "    zore_point = q_min - torch.round(x_min/scale)  # 四舍五入\n",
    "    zore_point = torch.clip(zore_point,q_min,q_max)\n",
    "\n",
    "    return QuantizationParams(scale=scale, zero_point=zore_point,q_min=q_min,q_max=q_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95ae2363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizationParams(scale=tensor(0.0146), zero_point=tensor(21.), q_min=-128, q_max=127)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取x的整体非量化参数，x_shape=[3,3]\n",
    "x_asym_params = get_asymmetric_qparams(x)\n",
    "x_asym_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87223d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizationParams(scale=tensor([[0.0146],\n",
       "        [0.0077],\n",
       "        [0.0061]]), zero_point=tensor([[ 21.],\n",
       "        [ 53.],\n",
       "        [-10.]]), q_min=-128, q_max=127)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以dim=0作为通道，逐通道获取x的非量化参数，每个通道维护其自身的s和z，x_shape=[3,3]\n",
    "x_asym_params = get_asymmetric_qparams(x,True,0)\n",
    "x_asym_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aaa30c",
   "metadata": {},
   "source": [
    "## 4.3 量化和反量化\n",
    "获取QuantizationParams之后对x进行量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63b82385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对输入的x进行量化，返回量化后的tensor （int8）\n",
    "def quantize_tensor(x: torch.Tensor, qparams: QuantizationParams) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    通用的量化函数：\n",
    "        q = clip(round(x / scale + zero_point), q_min, q_max)\n",
    "    支持 per-tensor 和 per-channel（通过广播）。\n",
    "    \"\"\"\n",
    "    scale = qparams.scale\n",
    "    zero_point = qparams.zero_point\n",
    "\n",
    "    # 确保能广播\n",
    "    # 如果是标量，则直接用；如果是 per-channel，应该已经带 keepdim=True\n",
    "    q = x / scale + zero_point\n",
    "    q = torch.round(q)\n",
    "    q = torch.clip(q, qparams.q_min, qparams.q_max)\n",
    "    q = q.to(torch.int8)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9bdf3b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193]]),torch.float32 \n",
      " \n",
      " q_sym: \n",
      " tensor([[  90,  -17, -127],\n",
      "        [  52,  -98, -127],\n",
      "        [  61,  127, -109]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# 对x进行对称量化，输出对称量化之后的参数q_sym\n",
    "q_sym = quantize_tensor(x,x_sym_params)\n",
    "print(f\"x: \\n {x},{x.dtype} \\n \\n q_sym: \\n {q_sym}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42d0a4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193]]),torch.float32 \n",
      " \n",
      " q_asym: \n",
      " tensor([[ 127,    1, -128],\n",
      "        [ 127,  -88, -128],\n",
      "        [  56,  127, -128]], dtype=torch.int8)\n"
     ]
    }
   ],
   "source": [
    "# 对x进行非对称量化，输出非对称量化之后的参数q_sym\n",
    "q_asym = quantize_tensor(x,x_asym_params)\n",
    "print(f\"x: \\n {x},{x.dtype} \\n \\n q_asym: \\n {q_asym}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "498c32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对量化后的q进行反量化输出x_hat\n",
    "def dequantize_tensor(q: torch.Tensor, qparams: QuantizationParams) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    通用反量化：\n",
    "        x_hat = (q - zero_point) * scale\n",
    "    \"\"\"\n",
    "    q = q.to(torch.float32)\n",
    "    scale = qparams.scale\n",
    "    zero_point = qparams.zero_point\n",
    "    x_hat = (q - zero_point) * scale\n",
    "    return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1a73d34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5440, -0.2916, -2.1788],\n",
       "        [ 0.5727, -1.0792, -1.3986],\n",
       "        [ 0.4025,  0.8380, -0.7193]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对对称量化之后的x进行反量化\n",
    "x_hat_sym = dequantize_tensor(q_sym,x_sym_params)\n",
    "x_hat_sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f138602a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5463, -0.2917, -2.1735],\n",
       "        [ 0.5708, -1.0877, -1.3962],\n",
       "        [ 0.4031,  0.8367, -0.7206]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对非对称量化之后的x进行反量化\n",
    "x_hat_asym = dequantize_tensor(q_asym,x_asym_params)\n",
    "x_hat_asym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c4d75346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err_x_sym: \n",
      " tensor([[ 3.0279e-03,  1.7799e-03,  0.0000e+00],\n",
      "        [ 4.2220e-03,  5.2912e-03,  0.0000e+00],\n",
      "        [-8.3023e-04,  0.0000e+00,  6.6161e-06]]) \n",
      " \n",
      " err_x_asym: \n",
      " tensor([[ 0.0053,  0.0017,  0.0053],\n",
      "        [ 0.0024, -0.0031,  0.0024],\n",
      "        [-0.0003, -0.0014, -0.0014]])\n"
     ]
    }
   ],
   "source": [
    "# 分别展示对称量化误差和非对称量化误差\n",
    "err_x_sym = x_hat_sym - x\n",
    "err_x_asym = x_hat_asym -x \n",
    "print(f\"err_x_sym: \\n {err_x_sym} \\n \\n err_x_asym: \\n {err_x_asym}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476d0c30",
   "metadata": {},
   "source": [
    "## 4.4 封装量化函数\n",
    "将量化函数进行封装，保留一个量化入口即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56541da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 量化+反量化函数入口\n",
    "def quantize_dequant(\n",
    "    x: torch.Tensor,\n",
    "    per_channel: bool = False,\n",
    "    channel_dim: int = 0,\n",
    "    dtype=torch.int8,\n",
    "    sym:bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    一步完成：对称量化 + 反量化\n",
    "    返回:\n",
    "        x_hat: 反量化后的近似 x\n",
    "        qparams: 量化参数，可重复使用\n",
    "    \"\"\"\n",
    "    if sym:\n",
    "        get_qparams = get_symmetric_qparams\n",
    "    else:\n",
    "        get_qparams = get_asymmetric_qparams\n",
    "    \n",
    "    # 获取量化参数\n",
    "    qparams = get_qparams(\n",
    "        x,\n",
    "        dtype=dtype,\n",
    "        per_channel=per_channel,\n",
    "        channel_dim=channel_dim,\n",
    "    )\n",
    "\n",
    "    # 量化\n",
    "    q = quantize_tensor(x, qparams)\n",
    "    # 反量化\n",
    "    x_hat = dequantize_tensor(q, qparams)\n",
    "    return q, x_hat, qparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3314fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193]])\n",
      "q_sym: \n",
      " tensor([[  90,  -17, -127],\n",
      "        [  33,  -63,  -82],\n",
      "        [  24,   49,  -42]], dtype=torch.int8)\n",
      "x_hat_sym: \n",
      " tensor([[ 1.5440, -0.2916, -2.1788],\n",
      "        [ 0.5661, -1.0808, -1.4068],\n",
      "        [ 0.4117,  0.8406, -0.7205]])\n",
      "x_sym_params: \n",
      " QuantizationParams(scale=tensor(0.0172), zero_point=tensor(0.), q_min=-128, q_max=127)\n"
     ]
    }
   ],
   "source": [
    "# 对称量化\n",
    "q_sym,x_hat_sym,x_sym_params = quantize_dequant(x)\n",
    "print(f\"x: \\n {x}\")\n",
    "print(f\"q_sym: \\n {q_sym}\")\n",
    "print(f\"x_hat_sym: \\n {x_hat_sym}\")\n",
    "print(f\"x_sym_params: \\n {x_sym_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "edb2538f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      " tensor([[ 1.5410, -0.2934, -2.1788],\n",
      "        [ 0.5684, -1.0845, -1.3986],\n",
      "        [ 0.4033,  0.8380, -0.7193]])\n",
      "q_asym: \n",
      " tensor([[ 127,    1, -128],\n",
      "        [  60,  -53,  -75],\n",
      "        [  49,   78,  -28]], dtype=torch.int8)\n",
      "x_hat_asym: \n",
      " tensor([[ 1.5463, -0.2917, -2.1735],\n",
      "        [ 0.5689, -1.0795, -1.4004],\n",
      "        [ 0.4084,  0.8315, -0.7148]])\n",
      "x_asym_params: \n",
      " QuantizationParams(scale=tensor(0.0146), zero_point=tensor(21.), q_min=-128, q_max=127)\n"
     ]
    }
   ],
   "source": [
    "# 非对称量化\n",
    "q_asym,x_hat_asym,x_asym_params = quantize_dequant(x,sym=False)\n",
    "print(f\"x: \\n {x}\")\n",
    "print(f\"q_asym: \\n {q_asym}\")\n",
    "print(f\"x_hat_asym: \\n {x_hat_asym}\")\n",
    "print(f\"x_asym_params: \\n {x_asym_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494dc64b",
   "metadata": {},
   "source": [
    "**将函数工具写入 util 目录下的 quant_tool.py 中**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7393e8c3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fquant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
