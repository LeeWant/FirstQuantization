{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d99413c",
   "metadata": {},
   "source": [
    "# 5 线性层量化\n",
    "在前面的过程中我们已经学习了对称量化和非对称量化，现在我们要尝试对模型中的线性层进行量化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "540d60af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import util.quant_tool as quant_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b80c5f",
   "metadata": {},
   "source": [
    "## 5.1 自定义量化模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c547e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义权重量化模块（per-channel 对称 int8 量化）\n",
    "class QuantLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    简化版的权重量化线性层：\n",
    "    - 只量化 weight（symmetric per-channel int8）\n",
    "    - bias 保持 FP32\n",
    "    - 前向时：先临时反量化，再用 F.linear\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        # # qweight: int8，形状 [out_features, in_features]\n",
    "        self.register_buffer(\n",
    "            \"qweight\",\n",
    "            torch.empty(out_features, in_features, dtype=torch.int8),\n",
    "        )\n",
    "        # scale: per-output-channel，形状 [out_features, 1]\n",
    "        self.register_buffer(\n",
    "            \"scale\",\n",
    "            torch.ones(out_features, 1, dtype=torch.float32),\n",
    "        )\n",
    "        # 对称量化 zero_point 固定 0，这里留个占位方便扩展\n",
    "        self.register_buffer(\n",
    "            \"zero_point\",\n",
    "            torch.zeros(out_features, 1, dtype=torch.float32),\n",
    "        )\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_features, dtype=torch.float32))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_linear(cls, linear: nn.Linear, per_channel: bool=False, is_symmetric: bool=True) -> \"QuantLinear\":\n",
    "        \"\"\"\n",
    "        给定一个 nn.Linear，构造对应的 QuantLinear 并完成权重量化。\n",
    "        \"\"\"\n",
    "        qlinear = cls(\n",
    "            in_features=linear.in_features,\n",
    "            out_features=linear.out_features,\n",
    "            bias=linear.bias is not None,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 获取线性层的权重\n",
    "            weight = linear.weight.data.detach().float().cpu()\n",
    "\n",
    "            if is_symmetric:\n",
    "                # 对线性层进行对称量化\n",
    "                qparams = quant_tool.get_symmetric_qparams(weight,per_channel)\n",
    "                qweight = quant_tool.quantize_tensor(weight,qparams)\n",
    "            else:\n",
    "                # 对线性层进行非对称量化\n",
    "                qparams = quant_tool.get_asymmetric_qparams(weight,per_channel)\n",
    "                qweight = quant_tool.quantize_tensor(weight,qparams)\n",
    "\n",
    "            # 储存缩放信息\n",
    "            qlinear.qweight.copy_(qweight)\n",
    "            qlinear.scale.copy_(qparams.scale)\n",
    "            qlinear.zero_point.copy_(qparams.zero_point)\n",
    "\n",
    "            # 对偏置项不做处理\n",
    "            if linear.bias is not None:\n",
    "                qlinear.bias.data.copy_(linear.bias.data.detach().float().cpu())\n",
    "        return qlinear\n",
    "\n",
    "    # 前向传播的时候需要进行反量化\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # 反量化得到近似权重：w_hat = (q - z) * scale\n",
    "        # qweight: [out, in], scale: [out, 1]\n",
    "        w_hat = (self.qweight.float()) * self.scale\n",
    "        return F.linear(x, w_hat, self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da7471b",
   "metadata": {},
   "source": [
    "## 5.2 定义模型量化入口\n",
    "输入一个模型，输出量化后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70433679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "# 对权重进行量化\n",
    "def quantize_model_weights(\n",
    "    model: nn.Module,\n",
    "    modules_to_exclude: Optional[List[str]] = None,  # 可选参数，排除不需要量化的层\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    递归遍历模型，遇到 nn.Linear 就替换成 QuantLinear（权重量化）。\n",
    "    可以通过 modules_to_exclude 按模块名排除不想量化的层。\n",
    "    \"\"\"\n",
    "    if modules_to_exclude is None:\n",
    "        modules_to_exclude = []\n",
    "\n",
    "    for name, child in list(model.named_children()):\n",
    "        full_name = name\n",
    "\n",
    "        if isinstance(child, nn.Linear) and full_name not in modules_to_exclude:\n",
    "            setattr(model, name, QuantLinear.from_linear(child))\n",
    "        else:\n",
    "            quantize_model_weights(child, modules_to_exclude=modules_to_exclude)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af414f92",
   "metadata": {},
   "source": [
    "## 5.3 对模型进行量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fdb3e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个多层线性层用于验证\n",
    "class FourLayerModel(nn.Module):\n",
    "    def __init__(self, input_size=64, hidden_size1=64, hidden_size2=128, hidden_size3=128, output_size=256):\n",
    "        super(FourLayerModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.layer3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.layer4 = nn.Linear(hidden_size3, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))  \n",
    "        x = torch.relu(self.layer2(x))  \n",
    "        x = torch.relu(self.layer3(x))  \n",
    "        x = self.layer4(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c397fe63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FourLayerModel(\n",
       "  (layer1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (layer2): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (layer3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (layer4): Linear(in_features=128, out_features=256, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FourLayerModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d8dee09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FourLayerModel(\n",
       "  (layer1): QuantLinear()\n",
       "  (layer2): QuantLinear()\n",
       "  (layer3): QuantLinear()\n",
       "  (layer4): QuantLinear()\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "base_model = copy.deepcopy(model)\n",
    "# 对模型进行量化,不排除层\n",
    "q_model = quantize_model_weights(base_model)\n",
    "q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "946f478b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FourLayerModel(\n",
       "  (layer1): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (layer2): QuantLinear()\n",
       "  (layer3): QuantLinear()\n",
       "  (layer4): QuantLinear()\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对模型进行量化,排除['layer1']层\n",
    "base_model = copy.deepcopy(model)\n",
    "q_model = quantize_model_weights(model=base_model,modules_to_exclude=['layer1'])\n",
    "q_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7577dd82",
   "metadata": {},
   "source": [
    "## 5.3 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aea5be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.35.0 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (4.35.0)\n",
      "Collecting accelerate==0.26.1\n",
      "  Downloading accelerate-0.26.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting seaborn==0.13.1\n",
      "  Downloading seaborn-0.13.1-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: filelock in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from transformers==4.35.0) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from transformers==4.35.0) (0.17.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from transformers==4.35.0) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from transformers==4.35.0) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from transformers==4.35.0) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from transformers==4.35.0) (2025.11.3)\n",
      "Requirement already satisfied: requests in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from transformers==4.35.0) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from transformers==4.35.0) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from transformers==4.35.0) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from transformers==4.35.0) (4.67.1)\n",
      "Requirement already satisfied: psutil in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from accelerate==0.26.1) (7.1.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from accelerate==0.26.1) (2.1.1)\n",
      "Collecting pandas>=1.2 (from seaborn==0.13.1)\n",
      "  Using cached pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
      "Collecting matplotlib!=3.6.1,>=3.4 (from seaborn==0.13.1)\n",
      "  Using cached matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: fsspec in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.0) (4.15.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.1)\n",
      "  Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.1)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.1)\n",
      "  Using cached fonttools-4.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (113 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.1)\n",
      "  Using cached kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.1)\n",
      "  Using cached pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting pyparsing>=3 (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.1)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn==0.13.1) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=1.2->seaborn==0.13.1)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=1.2->seaborn==0.13.1)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn==0.13.1) (1.17.0)\n",
      "Requirement already satisfied: sympy in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.26.1) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate==0.26.1) (12.9.86)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.26.1) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from requests->transformers==4.35.0) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from requests->transformers==4.35.0) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from requests->transformers==4.35.0) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from requests->transformers==4.35.0) (2025.11.12)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/lihao/.conda/envs/fquant/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.26.1) (1.3.0)\n",
      "Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
      "Downloading seaborn-0.13.1-py3-none-any.whl (294 kB)\n",
      "Using cached matplotlib-3.10.7-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "Using cached contourpy-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (325 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (4.9 MB)\n",
      "Using cached kiwisolver-1.4.9-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached pandas-2.3.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "Using cached pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "Using cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, pandas, matplotlib, seaborn, accelerate\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/12\u001b[0m [accelerate]2\u001b[0m [accelerate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-0.26.1 contourpy-1.3.2 cycler-0.12.1 fonttools-4.61.0 kiwisolver-1.4.9 matplotlib-3.10.7 pandas-2.3.3 pillow-12.0.0 pyparsing-3.2.5 pytz-2025.2 seaborn-0.13.1 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "# 安装transformers\n",
    "!pip install transformers==4.35.0 accelerate==0.26.1 seaborn==0.13.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "475e7e68",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_jieba_available' from 'transformers.utils.import_utils' (/home/lihao/.conda/envs/fquant/lib/python3.10/site-packages/transformers/utils/import_utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/fquant/lib/python3.10/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     logging,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     50\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/fquant/lib/python3.10/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n",
      "File \u001b[0;32m~/.conda/envs/fquant/lib/python3.10/site-packages/transformers/utils/__init__.py:92\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     ContextManagers,\n\u001b[1;32m     33\u001b[0m     ExplicitEnum,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m     working_or_temp_dir,\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     62\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     63\u001b[0m     DISABLE_TELEMETRY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     try_to_load_from_cache,\n\u001b[1;32m     91\u001b[0m )\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     93\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m     94\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[1;32m     95\u001b[0m     TORCH_FX_REQUIRED_VERSION,\n\u001b[1;32m     96\u001b[0m     USE_JAX,\n\u001b[1;32m     97\u001b[0m     USE_TF,\n\u001b[1;32m     98\u001b[0m     USE_TORCH,\n\u001b[1;32m     99\u001b[0m     DummyObject,\n\u001b[1;32m    100\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m    101\u001b[0m     _LazyModule,\n\u001b[1;32m    102\u001b[0m     ccl_version,\n\u001b[1;32m    103\u001b[0m     direct_transformers_import,\n\u001b[1;32m    104\u001b[0m     get_torch_version,\n\u001b[1;32m    105\u001b[0m     is_accelerate_available,\n\u001b[1;32m    106\u001b[0m     is_apex_available,\n\u001b[1;32m    107\u001b[0m     is_auto_awq_available,\n\u001b[1;32m    108\u001b[0m     is_auto_gptq_available,\n\u001b[1;32m    109\u001b[0m     is_bitsandbytes_available,\n\u001b[1;32m    110\u001b[0m     is_bs4_available,\n\u001b[1;32m    111\u001b[0m     is_coloredlogs_available,\n\u001b[1;32m    112\u001b[0m     is_cv2_available,\n\u001b[1;32m    113\u001b[0m     is_cython_available,\n\u001b[1;32m    114\u001b[0m     is_datasets_available,\n\u001b[1;32m    115\u001b[0m     is_decord_available,\n\u001b[1;32m    116\u001b[0m     is_detectron2_available,\n\u001b[1;32m    117\u001b[0m     is_essentia_available,\n\u001b[1;32m    118\u001b[0m     is_faiss_available,\n\u001b[1;32m    119\u001b[0m     is_flash_attn_2_available,\n\u001b[1;32m    120\u001b[0m     is_flax_available,\n\u001b[1;32m    121\u001b[0m     is_fsdp_available,\n\u001b[1;32m    122\u001b[0m     is_ftfy_available,\n\u001b[1;32m    123\u001b[0m     is_in_notebook,\n\u001b[1;32m    124\u001b[0m     is_ipex_available,\n\u001b[1;32m    125\u001b[0m     is_jieba_available,\n\u001b[1;32m    126\u001b[0m     is_jinja_available,\n\u001b[1;32m    127\u001b[0m     is_jumanpp_available,\n\u001b[1;32m    128\u001b[0m     is_kenlm_available,\n\u001b[1;32m    129\u001b[0m     is_keras_nlp_available,\n\u001b[1;32m    130\u001b[0m     is_levenshtein_available,\n\u001b[1;32m    131\u001b[0m     is_librosa_available,\n\u001b[1;32m    132\u001b[0m     is_natten_available,\n\u001b[1;32m    133\u001b[0m     is_ninja_available,\n\u001b[1;32m    134\u001b[0m     is_nltk_available,\n\u001b[1;32m    135\u001b[0m     is_onnx_available,\n\u001b[1;32m    136\u001b[0m     is_openai_available,\n\u001b[1;32m    137\u001b[0m     is_optimum_available,\n\u001b[1;32m    138\u001b[0m     is_pandas_available,\n\u001b[1;32m    139\u001b[0m     is_peft_available,\n\u001b[1;32m    140\u001b[0m     is_phonemizer_available,\n\u001b[1;32m    141\u001b[0m     is_pretty_midi_available,\n\u001b[1;32m    142\u001b[0m     is_protobuf_available,\n\u001b[1;32m    143\u001b[0m     is_psutil_available,\n\u001b[1;32m    144\u001b[0m     is_py3nvml_available,\n\u001b[1;32m    145\u001b[0m     is_pyctcdecode_available,\n\u001b[1;32m    146\u001b[0m     is_pytesseract_available,\n\u001b[1;32m    147\u001b[0m     is_pytest_available,\n\u001b[1;32m    148\u001b[0m     is_pytorch_quantization_available,\n\u001b[1;32m    149\u001b[0m     is_rjieba_available,\n\u001b[1;32m    150\u001b[0m     is_sacremoses_available,\n\u001b[1;32m    151\u001b[0m     is_safetensors_available,\n\u001b[1;32m    152\u001b[0m     is_sagemaker_dp_enabled,\n\u001b[1;32m    153\u001b[0m     is_sagemaker_mp_enabled,\n\u001b[1;32m    154\u001b[0m     is_scipy_available,\n\u001b[1;32m    155\u001b[0m     is_sentencepiece_available,\n\u001b[1;32m    156\u001b[0m     is_seqio_available,\n\u001b[1;32m    157\u001b[0m     is_sklearn_available,\n\u001b[1;32m    158\u001b[0m     is_soundfile_availble,\n\u001b[1;32m    159\u001b[0m     is_spacy_available,\n\u001b[1;32m    160\u001b[0m     is_speech_available,\n\u001b[1;32m    161\u001b[0m     is_sudachi_available,\n\u001b[1;32m    162\u001b[0m     is_tensorflow_probability_available,\n\u001b[1;32m    163\u001b[0m     is_tensorflow_text_available,\n\u001b[1;32m    164\u001b[0m     is_tf2onnx_available,\n\u001b[1;32m    165\u001b[0m     is_tf_available,\n\u001b[1;32m    166\u001b[0m     is_timm_available,\n\u001b[1;32m    167\u001b[0m     is_tokenizers_available,\n\u001b[1;32m    168\u001b[0m     is_torch_available,\n\u001b[1;32m    169\u001b[0m     is_torch_bf16_available,\n\u001b[1;32m    170\u001b[0m     is_torch_bf16_available_on_device,\n\u001b[1;32m    171\u001b[0m     is_torch_bf16_cpu_available,\n\u001b[1;32m    172\u001b[0m     is_torch_bf16_gpu_available,\n\u001b[1;32m    173\u001b[0m     is_torch_compile_available,\n\u001b[1;32m    174\u001b[0m     is_torch_cuda_available,\n\u001b[1;32m    175\u001b[0m     is_torch_fp16_available_on_device,\n\u001b[1;32m    176\u001b[0m     is_torch_fx_available,\n\u001b[1;32m    177\u001b[0m     is_torch_fx_proxy,\n\u001b[1;32m    178\u001b[0m     is_torch_mps_available,\n\u001b[1;32m    179\u001b[0m     is_torch_neuroncore_available,\n\u001b[1;32m    180\u001b[0m     is_torch_npu_available,\n\u001b[1;32m    181\u001b[0m     is_torch_tensorrt_fx_available,\n\u001b[1;32m    182\u001b[0m     is_torch_tf32_available,\n\u001b[1;32m    183\u001b[0m     is_torch_tpu_available,\n\u001b[1;32m    184\u001b[0m     is_torch_xpu_available,\n\u001b[1;32m    185\u001b[0m     is_torchaudio_available,\n\u001b[1;32m    186\u001b[0m     is_torchdistx_available,\n\u001b[1;32m    187\u001b[0m     is_torchdynamo_available,\n\u001b[1;32m    188\u001b[0m     is_torchvision_available,\n\u001b[1;32m    189\u001b[0m     is_training_run_on_sagemaker,\n\u001b[1;32m    190\u001b[0m     is_vision_available,\n\u001b[1;32m    191\u001b[0m     requires_backends,\n\u001b[1;32m    192\u001b[0m     tf_required,\n\u001b[1;32m    193\u001b[0m     torch_only_method,\n\u001b[1;32m    194\u001b[0m     torch_required,\n\u001b[1;32m    195\u001b[0m )\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpeft_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    197\u001b[0m     ADAPTER_CONFIG_NAME,\n\u001b[1;32m    198\u001b[0m     ADAPTER_SAFE_WEIGHTS_NAME,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    201\u001b[0m     find_adapter_config_file,\n\u001b[1;32m    202\u001b[0m )\n\u001b[1;32m    205\u001b[0m WEIGHTS_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch_model.bin\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'is_jieba_available' from 'transformers.utils.import_utils' (/home/lihao/.conda/envs/fquant/lib/python3.10/site-packages/transformers/utils/import_utils.py)"
     ]
    }
   ],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d475beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fquant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
