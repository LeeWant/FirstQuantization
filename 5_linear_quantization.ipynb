{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d99413c",
   "metadata": {},
   "source": [
    "# 5 线性层量化\n",
    "在前面的过程中我们已经学习了对称量化和非对称量化，现在我们要尝试对模型中的线性层进行量化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "540d60af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import util.quant_tool as quant_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b80c5f",
   "metadata": {},
   "source": [
    "## 5.1 自定义量化模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0c547e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义权重量化模块（per-channel 对称 int8 量化）\n",
    "class QuantLinear(nn.Module):\n",
    "    \"\"\"\n",
    "    简化版的权重量化线性层：\n",
    "    - 只量化 weight（symmetric per-channel int8）\n",
    "    - bias 保持 FP32\n",
    "    - 前向时：先临时反量化，再用 F.linear\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "\n",
    "        # # qweight: int8，形状 [out_features, in_features]\n",
    "        self.register_buffer(\n",
    "            \"qweight\",\n",
    "            torch.empty(out_features, in_features, dtype=torch.int8),\n",
    "        )\n",
    "        # scale: per-output-channel，形状 [out_features, 1]\n",
    "        self.register_buffer(\n",
    "            \"scale\",\n",
    "            torch.ones(out_features, 1, dtype=torch.float32),\n",
    "        )\n",
    "        # 对称量化 zero_point 固定 0，这里留个占位方便扩展\n",
    "        self.register_buffer(\n",
    "            \"zero_point\",\n",
    "            torch.zeros(out_features, 1, dtype=torch.float32),\n",
    "        )\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_features, dtype=torch.float32))\n",
    "        else:\n",
    "            self.bias = None\n",
    "\n",
    "    @classmethod\n",
    "    def from_linear(cls, linear: nn.Linear, per_channel: bool=False, is_symmetric: bool=True) -> \"QuantLinear\":\n",
    "        \"\"\"\n",
    "        给定一个 nn.Linear，构造对应的 QuantLinear 并完成权重量化。\n",
    "        \"\"\"\n",
    "        qlinear = cls(\n",
    "            in_features=linear.in_features,\n",
    "            out_features=linear.out_features,\n",
    "            bias=linear.bias is not None,\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # 获取线性层的权重\n",
    "            weight = linear.weight.data.detach().float().cpu()\n",
    "\n",
    "            if is_symmetric:\n",
    "                # 对线性层进行对称量化\n",
    "                qparams = quant_tool.get_symmetric_qparams(weight,per_channel)\n",
    "                qweight = quant_tool.quantize_tensor(weight,qparams)\n",
    "            else:\n",
    "                # 对线性层进行非对称量化\n",
    "                qparams = quant_tool.get_asymmetric_qparams(weight,per_channel)\n",
    "                qweight = quant_tool.quantize_tensor(weight,qparams)\n",
    "\n",
    "            # 储存缩放信息\n",
    "            qlinear.qweight.copy_(qweight)\n",
    "            qlinear.scale.copy_(qparams.scale)\n",
    "            qlinear.zero_point.copy_(qparams.zero_point)\n",
    "\n",
    "            # 对偏置项不做处理\n",
    "            if linear.bias is not None:\n",
    "                qlinear.bias.data.copy_(linear.bias.data.detach().float().cpu())\n",
    "        return qlinear\n",
    "\n",
    "    # 前向传播的时候需要进行反量化\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # 反量化得到近似权重：w_hat = (q - z) * scale\n",
    "        # qweight: [out, in], scale: [out, 1]\n",
    "        w_hat = (self.qweight.float()) * self.scale\n",
    "        return F.linear(x, w_hat, self.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da7471b",
   "metadata": {},
   "source": [
    "## 5.2 定义模型量化入口\n",
    "输入一个模型，输出量化后的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70433679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "# 对权重进行量化\n",
    "def quantize_model_weights(\n",
    "    model: nn.Module,\n",
    "    is_symmetric:bool=True,\n",
    "    modules_to_exclude: Optional[List[str]] = None,  # 可选参数，排除不需要量化的层\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    递归遍历模型，遇到 nn.Linear 就替换成 QuantLinear（权重量化）。\n",
    "    可以通过 modules_to_exclude 按模块名排除不想量化的层。\n",
    "    \"\"\"\n",
    "    if modules_to_exclude is None:\n",
    "        modules_to_exclude = []\n",
    "\n",
    "    for name, child in list(model.named_children()):\n",
    "        full_name = name\n",
    "\n",
    "        if isinstance(child, nn.Linear) and full_name not in modules_to_exclude:\n",
    "            setattr(model, name, QuantLinear.from_linear(child,is_symmetric))\n",
    "        else:\n",
    "            quantize_model_weights(child, modules_to_exclude=modules_to_exclude)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af414f92",
   "metadata": {},
   "source": [
    "## 5.3 对模型进行量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5fdb3e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个多层线性层用于验证\n",
    "class FourLayerModel(nn.Module):\n",
    "    def __init__(self, input_size=64):\n",
    "        super(FourLayerModel, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 128)\n",
    "        self.layer2 = nn.Linear(128, 256)\n",
    "        self.layer3 = nn.Linear(256, 128)\n",
    "        self.layer4 = nn.Linear(128, 1)\n",
    "        self.layer5 = nn.Linear(1, 9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))  \n",
    "        x = torch.relu(self.layer2(x))  \n",
    "        x = torch.relu(self.layer3(x))  \n",
    "        x = torch.relu(self.layer4(x))  \n",
    "        x = self.layer5(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c397fe63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FourLayerModel(\n",
       "  (layer1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (layer2): Linear(in_features=128, out_features=256, bias=True)\n",
       "  (layer3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (layer4): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (layer5): Linear(in_features=1, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FourLayerModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "133b5004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FourLayerModel(\n",
       "  (layer1): Linear(in_features=64, out_features=128, bias=True)\n",
       "  (layer2): QuantLinear()\n",
       "  (layer3): QuantLinear()\n",
       "  (layer4): QuantLinear()\n",
       "  (layer5): Linear(in_features=1, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对模型进行量化,排除['layer1']层\n",
    "base_model = copy.deepcopy(model)\n",
    "q_model = quantize_model_weights(model=base_model,modules_to_exclude=['layer1','layer5'])\n",
    "q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d8dee09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FourLayerModel(\n",
       "  (layer1): QuantLinear()\n",
       "  (layer2): QuantLinear()\n",
       "  (layer3): QuantLinear()\n",
       "  (layer4): QuantLinear()\n",
       "  (layer5): QuantLinear()\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy\n",
    "base_model = copy.deepcopy(model)\n",
    "# 对模型进行量化,不排除层\n",
    "q_model = quantize_model_weights(base_model)\n",
    "q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27e6716b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9708,  0.5421,  1.0840, -0.0047,  0.1527,  0.7801,  2.0204, -0.1570,\n",
       "          1.4731,  1.1514, -0.9850,  1.7130, -1.8669, -1.0876,  1.4048, -0.4458,\n",
       "          0.1398, -0.4947,  0.5127, -0.4818, -0.8740,  1.6020,  0.4836, -0.8855,\n",
       "         -0.6367, -0.4623, -1.4764, -1.1121,  0.0138, -0.8910, -1.4673,  0.1777,\n",
       "          0.6252, -0.8003, -0.0221,  0.5497, -1.0890,  1.2884,  0.6866,  1.0233,\n",
       "          0.6059,  1.3729,  0.1450,  1.2973, -0.5043,  0.0220,  0.6940, -0.1463,\n",
       "         -0.0866,  1.4762, -0.0066, -0.0279, -0.1981,  0.9113, -0.2384,  0.6656,\n",
       "         -0.1552,  0.8052,  0.2919, -1.1599, -0.1969,  0.2914, -0.2966, -0.0989]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化随机输入\n",
    "input_data = torch.randn(1,64)\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3598219c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4874, -0.8665,  0.0766, -0.7997,  0.3351, -0.6136, -0.2721, -0.9806,\n",
       "          0.1873]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型量化前输出\n",
    "model.eval()\n",
    "# 禁用梯度计算，进行推理\n",
    "with torch.no_grad():\n",
    "    output = model(input_data)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6df07445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4878, -0.8664,  0.0770, -0.7996,  0.3353, -0.6140, -0.2726, -0.9802,\n",
       "          0.1872]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 模型量化后输出\n",
    "q_model.eval()\n",
    "# 禁用梯度计算，进行推理\n",
    "with torch.no_grad():\n",
    "    sym_output = q_model(input_data)\n",
    "sym_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9a7fe3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "err: \n",
      " tensor([[ 0.3647, -0.1088, -0.3959, -0.0354, -0.2068,  0.4053,  0.4546, -0.4076,\n",
      "          0.1279]]) \n"
     ]
    }
   ],
   "source": [
    "# 计算误差，差值较小有时候会省略显示，通过 * 1000 放大误差用于展示\n",
    "err = output - sym_output\n",
    "print(f\"err: \\n {err * 1000} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d0289",
   "metadata": {},
   "source": [
    "### 以上方法已被装入quant_tool可直接通过quant_tool进行调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387dad68",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fquant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
